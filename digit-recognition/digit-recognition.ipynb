{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Note: The next command will run digitrec.py, building and compiling a neural network, running the training dataset through it, and reading random selections from the test dataset in order to show the networks accuracy</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import all the nessessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as kr\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as pre\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialise the network using the sequential model, basically meaning we can add layers to the initialised network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to add the layers, in our case we want 784 input neurons (one for each pixel of our 24x24 image), 1000 neurons on a hidden inner layer, and another 400 neurons on a second hidden inner layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of neurons internal to the network is completely up to you, in fact, tweaking the number of layers and neurons can help improve the networks performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(kr.layers.Dense(units=1000, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to add 10 output neurons, one for each possible digit the image could be containing (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compile the network, connecting all of the neurons to each of it's neighbouring layers neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in my mnist dataset notebook, we must unzip the files containing the images, and corrisponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_images = f.read()\n",
    "    \n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_labels = f.read()\n",
    "    \n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    training_images = f.read()\n",
    "    \n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    training_labels = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to read the datasets into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = ~np.array(list(training_images[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "training_labels =  np.array(list(training_labels[8:])).astype(np.uint8)\n",
    "\n",
    "test_images = ~np.array(list(test_images[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_labels = np.array(list(test_labels[8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the images in an array by showing all white pixels as 0, and all other pixels as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ~np.array(list(test_images[16:])).reshape(10000, 28, 28).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print((~image[0]).astype(np.bool).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to put each pixel into a corrisponding neuron in the inputs of the network, we have to flatten the datasets into single arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_inputs = training_images.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels need to be set up next, first we must encode the data, turning all the label dataset into binary values, and all in a 10x10 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = pre.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_outputs = encoder.transform(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both datasets set up, we are ready to start training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.7436 - acc: 0.7886\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.3929 - acc: 0.8874\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.3433 - acc: 0.8997\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.3128 - acc: 0.9097\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.2929 - acc: 0.9145\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.2734 - acc: 0.9207\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.2578 - acc: 0.9262\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 20s 328us/step - loss: 0.2431 - acc: 0.9300\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.2310 - acc: 0.9338\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.2182 - acc: 0.9383\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.2074 - acc: 0.9407\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.1977 - acc: 0.9440\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.1882 - acc: 0.9462\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.1800 - acc: 0.9483\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.1719 - acc: 0.9502\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.1647 - acc: 0.9525\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.1588 - acc: 0.9545\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 20s 329us/step - loss: 0.1522 - acc: 0.9567\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 19s 324us/step - loss: 0.1465 - acc: 0.9586\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.1414 - acc: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b016e1f98>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(neuron_inputs, neuron_outputs, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now have a working neural network, let's try and test manually to see how well the network works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "The actual number: =>>  [6]\n",
      "The network reads: =>>  [6]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [4]\n",
      "The network reads: =>>  [4]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [9]\n",
      "The network reads: =>>  [9]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [3]\n",
      "The network reads: =>>  [3]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [1]\n",
      "The network reads: =>>  [1]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [2]\n",
      "The network reads: =>>  [2]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [7]\n",
      "The network reads: =>>  [7]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [2]\n",
      "The network reads: =>>  [2]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [8]\n",
      "The network reads: =>>  [8]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [3]\n",
      "The network reads: =>>  [3]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [8]\n",
      "The network reads: =>>  [8]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [0]\n",
      "The network reads: =>>  [0]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [8]\n",
      "The network reads: =>>  [8]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [8]\n",
      "The network reads: =>>  [8]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [4]\n",
      "The network reads: =>>  [4]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [2]\n",
      "The network reads: =>>  [2]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [6]\n",
      "The network reads: =>>  [6]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [9]\n",
      "The network reads: =>>  [9]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [1]\n",
      "The network reads: =>>  [1]\n",
      "=================================\n",
      "=================================\n",
      "The actual number: =>>  [8]\n",
      "The network reads: =>>  [8]\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "for i in range(20): #Run 20 tests\n",
    "    print(\"=================================\")\n",
    "    randIndex = randint(0, 9999) #Get a random index to pull an image from\n",
    "    test = model.predict(test_images[randIndex:randIndex+1]) #Pull the image from the dataset\n",
    "    result = test.argmax(axis=1) #Set result to the highest array value\n",
    "    print(\"The actual number: =>> \", test_labels[randIndex:randIndex+1])\n",
    "    print(\"The network reads: =>> \", result)\n",
    "    print(\"=================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
